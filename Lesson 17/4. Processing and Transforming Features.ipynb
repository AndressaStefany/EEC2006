{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "==\n",
    "\n",
    "To understand how linear regression works, we've stuck to using features from the training dataset that contained no missing values and were already in a convenient numeric representation. In this mission, we'll explore how to transform some of the the remaining features so we can use them in our model. Broadly, the process of processing and creating new features is known as [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering). Feature engineering is a bit of an art and having knowledge in the specific domain (in this case real estate) can help you create better features. In this mission, we'll focus on some domain-independent strategies that work for all problems.\n",
    "\n",
    "In the first half of this mission, we'll focus only on columns that contain no missing values but still aren't in the proper format to use in a linear regression model. In the latter half of this mission, we'll explore some ways to deal with missing values.\n",
    "\n",
    "Amongst the columns that don't contain missing values, some of the common issues include:\n",
    "\n",
    "- the column is not numerical (e.g. a zoning code represented using text)\n",
    "- the column is numerical but not ordinal (e.g. zip code values)\n",
    "- the column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    "\n",
    "Let's start by filtering the training set to just the columns containing no missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Area Street Lot Shape  \\\n",
       "0      1  526301100           20        RL     31770   Pave       IR1   \n",
       "1      2  526350040           20        RH     11622   Pave       Reg   \n",
       "2      3  526351010           20        RL     14267   Pave       IR1   \n",
       "3      4  526353030           20        RL     11160   Pave       Reg   \n",
       "4      5  527105010           60        RL     13830   Pave       IR1   \n",
       "\n",
       "  Land Contour Utilities Lot Config    ...     Enclosed Porch 3Ssn Porch  \\\n",
       "0          Lvl    AllPub     Corner    ...                  0          0   \n",
       "1          Lvl    AllPub     Inside    ...                  0          0   \n",
       "2          Lvl    AllPub     Corner    ...                  0          0   \n",
       "3          Lvl    AllPub     Corner    ...                  0          0   \n",
       "4          Lvl    AllPub     Inside    ...                  0          0   \n",
       "\n",
       "  Screen Porch Pool Area Misc Val Mo Sold  Yr Sold  Sale Type  Sale Condition  \\\n",
       "0            0         0        0       5     2010        WD           Normal   \n",
       "1          120         0        0       6     2010        WD           Normal   \n",
       "2            0         0    12500       6     2010        WD           Normal   \n",
       "3            0         0        0       4     2010        WD           Normal   \n",
       "4            0         0        0       3     2010        WD           Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  \n",
       "3     244000  \n",
       "4     189900  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "\n",
    "df_no_mv = train[train_null_counts[train_null_counts==0].index]\n",
    "df_no_mv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Categorical features\n",
    "==\n",
    "\n",
    "You'll notice that some of the columns in the data frame **df_no_mv** contain string values. If these columns contain only a limited set of uniuqe values, they're known as **categorical features**. As the name suggests, a categorical feature groups a specific training example into a specific category. Here are some examples from the dataset:\n",
    "\n",
    ">```python\n",
    ">>> train['Utilities'].value_counts()\n",
    "AllPub    1457\n",
    "NoSewr       2\n",
    "NoSeWa       1\n",
    "Name: Utilities, dtype: int64\n",
    ">>> train['Street'].value_counts()\n",
    "Pave    1455\n",
    "Grvl       5\n",
    ">>> train['House Style'].value_counts()\n",
    "1Story    743\n",
    "2Story    440\n",
    "1.5Fin    160\n",
    "SLvl       60\n",
    "SFoyer     35\n",
    "2.5Unf     11\n",
    "1.5Unf      8\n",
    "2.5Fin      3\n",
    "```\n",
    "\n",
    "To use these features in our model, we need to transform them into numerical representations. Thankfully, pandas makes this easy because the library has a special categorical data type. We can convert any column that contains no missing values (or an error will be thrown) to the categorical data type using the **pandas.Series.astype()** method:\n",
    "\n",
    ">```python\n",
    ">>> train['Utilities'] = train['Utilities'].astype('category')\n",
    "```\n",
    "\n",
    "When a column is converted to the categorical data type, pandas assigns a code to each unique value in the column. Unless we access these values directly, most of the pandas manipulation operations that work for string columns will work for categorical ones as well.\n",
    "\n",
    ">```python\n",
    ">>> train['Utilities']\n",
    "0       AllPub\n",
    "1       AllPub\n",
    "2       AllPub\n",
    "3       AllPub\n",
    "4       AllPub\n",
    "5       AllPub\n",
    "...\n",
    "```\n",
    "\n",
    "We need to use the **.cat** accessor followed by the **.codes** property to actually access the underlying numerical representation of a column:\n",
    "\n",
    ">```python\n",
    ">>> train['Utilities'].cat.codes\n",
    "```\n",
    "\n",
    "Let's convert all of the text columns that contain no missing values into the categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MS Zoning', 'Street', 'Lot Shape', 'Land Contour', 'Utilities',\n",
       "       'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1',\n",
       "       'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl',\n",
       "       'Exterior 1st', 'Exterior 2nd', 'Exter Qual', 'Exter Cond',\n",
       "       'Foundation', 'Heating', 'Heating QC', 'Central Air', 'Electrical',\n",
       "       'Kitchen Qual', 'Functional', 'Paved Drive', 'Sale Type',\n",
       "       'Sale Condition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cols = df_no_mv.select_dtypes(include=['object']).columns\n",
    "text_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS Zoning: 6\n",
      "Street: 2\n",
      "Lot Shape: 4\n",
      "Land Contour: 4\n",
      "Utilities: 3\n",
      "Lot Config: 5\n",
      "Land Slope: 3\n",
      "Neighborhood: 26\n",
      "Condition 1: 9\n",
      "Condition 2: 6\n",
      "Bldg Type: 5\n",
      "House Style: 8\n",
      "Roof Style: 6\n",
      "Roof Matl: 5\n",
      "Exterior 1st: 14\n",
      "Exterior 2nd: 16\n",
      "Exter Qual: 4\n",
      "Exter Cond: 5\n",
      "Foundation: 6\n",
      "Heating: 6\n",
      "Heating QC: 4\n",
      "Central Air: 2\n",
      "Electrical: 4\n",
      "Kitchen Qual: 5\n",
      "Functional: 7\n",
      "Paved Drive: 3\n",
      "Sale Type: 9\n",
      "Sale Condition: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanovitch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1457\n",
       "2       2\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in text_cols:\n",
    "    print(col+\":\", len(train[col].unique()))\n",
    "for col in text_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "train['Utilities'].cat.codes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dummy Coding\n",
    "==\n",
    "\n",
    "When we convert a column to the categorical data type, pandas assigns a number from **0** to **n-1** (where **n** is the number of unique values in a column) for each value. The drawback with this approach is that one of the assumptions of linear regression is violated here. Linear regression operates under the assumption that the features are linearly correlated with the target column. For a categorical feature, however, there's no actual numerical meaning to the categorical codes that pandas assigned for that colum. An increase in the **Utilities** column from **1** to **2** has no correlation value with the target column, and the categorical codes are instead used for uniqueness and exclusivity (the category associated with **0** is different than the one associated with **1**).\n",
    "\n",
    "The common solution is to use a technique called [dummy coding](https://en.wikipedia.org/wiki/Dummy_variable_%28statistics%29). Instead of having a single column with **n** integer codes, we have **n** binary columns. Here's what that would look like for the **Utilities** column:\n",
    "\n",
    "| Utilities_AllPub  | Utilities_NoSewr | Utilities_NoSeWa  |\n",
    "|-----------------------------------|------------------|---|\n",
    "| 1                                 | 0                | 0 |\n",
    "| 1                                 | 0                | 0 |\n",
    "| 1                                 | 0                | 0 |\n",
    "| 1                                 | 0                | 0 |\n",
    "\n",
    "\n",
    "Because the original values for the first 4 rows were **AllPub**, in the new scheme, they contain the binary value for true (**1**) in the **Utilities_AllPub** column and **0** for the other 2 columns.\n",
    "\n",
    "Pandas thankfully has a convenience method to help us apply this transformation for all of the text columns called **pandas.get_dummies()**:\n",
    "\n",
    ">```python\n",
    "dummy_cols = pd.get_dummies()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cols = pd.DataFrame()\n",
    "for col in text_cols:\n",
    "    col_dummies = pd.get_dummies(train[col])\n",
    "    train = pd.concat([train, col_dummies], axis=1)\n",
    "    del train[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Missing Values\n",
    "==\n",
    "\n",
    "In the next few screens, we'll focus on handling columns with missing values. When values are missing in a column, there are two main approaches we can take:\n",
    "\n",
    "- Remove rows containing missing values for specific columns\n",
    "    - Pro: Rows containing missing values are removed, leaving only clean data for modeling\n",
    "    - Con: Entire observations from the training set are removed, which can reduce overall prediction accuracy\n",
    "- Impute (or replace) missing values using a descriptive statistic from the column\n",
    "    - Pro: Missing values are replaced with potentially similar estimates, preserving the rest of the observation in the model.\n",
    "    - Con: Depending on the approach, we may be adding noisy data for the model to learn\n",
    "\n",
    "Given that we only have 1460 training examples (with ~80 potentially useful features), we don't want to remove any of these rows from the dataset. Let's instead focus on **imputation** techniques.\n",
    "\n",
    "We'll focus on columns that contain at least 1 missing value but less than 365 missing values (or 25% of the number of rows in the training set). There's no strict threshold, and many people instead use a 50% cutoff (if half the values in a column are missing, it's automatically dropped). Having some domain knowledge can help with determining an acceptable cutoff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      249\n",
      "Mas Vnr Type       11\n",
      "Mas Vnr Area       11\n",
      "Bsmt Qual          40\n",
      "Bsmt Cond          40\n",
      "Bsmt Exposure      41\n",
      "BsmtFin Type 1     40\n",
      "BsmtFin SF 1        1\n",
      "BsmtFin Type 2     41\n",
      "BsmtFin SF 2        1\n",
      "Bsmt Unf SF         1\n",
      "Total Bsmt SF       1\n",
      "Bsmt Full Bath      1\n",
      "Bsmt Half Bath      1\n",
      "Garage Type        74\n",
      "Garage Yr Blt      75\n",
      "Garage Finish      75\n",
      "Garage Qual        75\n",
      "Garage Cond        75\n",
      "dtype: int64\n",
      "Lot Frontage      float64\n",
      "Mas Vnr Type       object\n",
      "Mas Vnr Area      float64\n",
      "Bsmt Qual          object\n",
      "Bsmt Cond          object\n",
      "Bsmt Exposure      object\n",
      "BsmtFin Type 1     object\n",
      "BsmtFin SF 1      float64\n",
      "BsmtFin Type 2     object\n",
      "BsmtFin SF 2      float64\n",
      "Bsmt Unf SF       float64\n",
      "Total Bsmt SF     float64\n",
      "Bsmt Full Bath    float64\n",
      "Bsmt Half Bath    float64\n",
      "Garage Type        object\n",
      "Garage Yr Blt     float64\n",
      "Garage Finish      object\n",
      "Garage Qual        object\n",
      "Garage Cond        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "df_missing_values = train[train_null_counts[(train_null_counts>0) &\n",
    "                                            (train_null_counts<584)].index]\n",
    "\n",
    "print(df_missing_values.isnull().sum())\n",
    "print(df_missing_values.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Imputing Missing Values\n",
    "==\n",
    "\n",
    "It looks like about half of the columns in **df_missing_values** are string columns (**object** data type), while about half are **float64** columns. For numerical columns with missing values, a common strategy is to compute the mean, median, or mode of each column and replace all missing values in that column with that value.\n",
    "\n",
    "Because imputation is a common task, pandas contains a [pandas.DataFrame.fillna()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) method that we can use for this. If we pass in a value, all of the missing values (**NaN**) in the data frame are replaced by that value:\n",
    "\n",
    ">```python\n",
    "# Only select float columns.\n",
    "missing_floats = df_missing_vals.select_dtypes(include=['float'])\n",
    "# Returns a data frame with missing values replaced with 0.\n",
    "fill_with_zero = missing_floats.fillna(0)\n",
    "```\n",
    "\n",
    "You can also pass in a column-wise summarization function and fill in missing values that way:\n",
    "\n",
    "\n",
    ">```python\n",
    "# Returns a data frame with missing values replaced with mean of that column.\n",
    "fill_with_mean = missing_floats.fillna(missing_floats.mean())\n",
    "```\n",
    "\n",
    "Let's impute all of the missing values in float columns with each column's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      0\n",
      "Mas Vnr Area      0\n",
      "BsmtFin SF 1      0\n",
      "BsmtFin SF 2      0\n",
      "Bsmt Unf SF       0\n",
      "Total Bsmt SF     0\n",
      "Bsmt Full Bath    0\n",
      "Bsmt Half Bath    0\n",
      "Garage Yr Blt     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "float_cols = df_missing_values.select_dtypes(include=['float'])\n",
    "float_cols = float_cols.fillna(df_missing_values.mean())\n",
    "print(float_cols.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Next Steps\n",
    "==\n",
    "\n",
    "In this mission, we explored a few different techniques for transforming features into appropriate representations for a linear regression model. Next in this course is a guided project, where you'll practice the techniques you've learned in this course to build better linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
